{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0bd152b-3084-4408-b5f8-80f7c69c081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_INPUT = 'resume_screen.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a84b58c9-8567-4442-b5b6-7a2de31bef52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e5f17112-120b-409c-8f70-0a5cdd267fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_INPUT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "37e65ca4-0a95-4b38-aeb9-5facbf89abc7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>advance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.500125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           advance\n",
       "count  2000.000000\n",
       "mean      0.500000\n",
       "std       0.500125\n",
       "min       0.000000\n",
       "25%       0.000000\n",
       "50%       0.500000\n",
       "75%       1.000000\n",
       "max       1.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f55c5a5e-8e1d-4669-bcdd-34cf6b61f86d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>resume_text_256</th>\n",
       "      <th>jd_text_128</th>\n",
       "      <th>job_family</th>\n",
       "      <th>seniority</th>\n",
       "      <th>advance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RS00000</td>\n",
       "      <td>8+ years experience; key skills: linux, contai...</td>\n",
       "      <td>We are hiring a Senior DevOps professional. Mu...</td>\n",
       "      <td>DevOps</td>\n",
       "      <td>Senior</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RS00001</td>\n",
       "      <td>0+ years experience; key skills: kafka, ci/cd,...</td>\n",
       "      <td>We are hiring a Junior PM professional. Must h...</td>\n",
       "      <td>PM</td>\n",
       "      <td>Junior</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RS00002</td>\n",
       "      <td>0+ years experience; key skills: bug-tracking,...</td>\n",
       "      <td>We are hiring a Junior QA professional. Must h...</td>\n",
       "      <td>QA</td>\n",
       "      <td>Junior</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RS00003</td>\n",
       "      <td>2+ years experience; key skills: test-cases, b...</td>\n",
       "      <td>We are hiring a Mid QA professional. Must have...</td>\n",
       "      <td>QA</td>\n",
       "      <td>Mid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RS00004</td>\n",
       "      <td>9+ years experience; key skills: testing, bug-...</td>\n",
       "      <td>We are hiring a Senior QA professional. Must h...</td>\n",
       "      <td>QA</td>\n",
       "      <td>Senior</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>RS01995</td>\n",
       "      <td>1+ years experience; key skills: java, databas...</td>\n",
       "      <td>We are hiring a Junior Backend professional. M...</td>\n",
       "      <td>Backend</td>\n",
       "      <td>Junior</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>RS01996</td>\n",
       "      <td>6+ years experience; key skills: databases, ja...</td>\n",
       "      <td>We are hiring a Senior Backend professional. M...</td>\n",
       "      <td>Backend</td>\n",
       "      <td>Senior</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>RS01997</td>\n",
       "      <td>4+ years experience; key skills: javascript, h...</td>\n",
       "      <td>We are hiring a Mid Frontend professional. Mus...</td>\n",
       "      <td>Frontend</td>\n",
       "      <td>Mid</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>RS01998</td>\n",
       "      <td>8+ years experience; key skills: metrics, data...</td>\n",
       "      <td>We are hiring a Senior Backend professional. M...</td>\n",
       "      <td>Backend</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>RS01999</td>\n",
       "      <td>6+ years experience; key skills: containers, r...</td>\n",
       "      <td>We are hiring a Senior DevOps professional. Mu...</td>\n",
       "      <td>DevOps</td>\n",
       "      <td>Senior</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id                                    resume_text_256  \\\n",
       "0     RS00000  8+ years experience; key skills: linux, contai...   \n",
       "1     RS00001  0+ years experience; key skills: kafka, ci/cd,...   \n",
       "2     RS00002  0+ years experience; key skills: bug-tracking,...   \n",
       "3     RS00003  2+ years experience; key skills: test-cases, b...   \n",
       "4     RS00004  9+ years experience; key skills: testing, bug-...   \n",
       "...       ...                                                ...   \n",
       "1995  RS01995  1+ years experience; key skills: java, databas...   \n",
       "1996  RS01996  6+ years experience; key skills: databases, ja...   \n",
       "1997  RS01997  4+ years experience; key skills: javascript, h...   \n",
       "1998  RS01998  8+ years experience; key skills: metrics, data...   \n",
       "1999  RS01999  6+ years experience; key skills: containers, r...   \n",
       "\n",
       "                                            jd_text_128 job_family seniority  \\\n",
       "0     We are hiring a Senior DevOps professional. Mu...     DevOps    Senior   \n",
       "1     We are hiring a Junior PM professional. Must h...         PM    Junior   \n",
       "2     We are hiring a Junior QA professional. Must h...         QA    Junior   \n",
       "3     We are hiring a Mid QA professional. Must have...         QA       Mid   \n",
       "4     We are hiring a Senior QA professional. Must h...         QA    Senior   \n",
       "...                                                 ...        ...       ...   \n",
       "1995  We are hiring a Junior Backend professional. M...    Backend    Junior   \n",
       "1996  We are hiring a Senior Backend professional. M...    Backend    Senior   \n",
       "1997  We are hiring a Mid Frontend professional. Mus...   Frontend       Mid   \n",
       "1998  We are hiring a Senior Backend professional. M...    Backend    Senior   \n",
       "1999  We are hiring a Senior DevOps professional. Mu...     DevOps    Senior   \n",
       "\n",
       "      advance  \n",
       "0           1  \n",
       "1           0  \n",
       "2           1  \n",
       "3           1  \n",
       "4           1  \n",
       "...       ...  \n",
       "1995        1  \n",
       "1996        1  \n",
       "1997        1  \n",
       "1998        0  \n",
       "1999        0  \n",
       "\n",
       "[2000 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "77d609ee-dba8-4348-83fd-9796bf29b386",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09080525ff4c4c2d99e9f9bcd3f35fd9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0179217cfd7416c833a7711f95134ff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758166394.340706   50603 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1655 MB memory:  -> device: 0, name: AMD Radeon RX 7900 XTX, pci bus id: 0000:03:00.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ resume_input        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jd_input            │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ job_family_input    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ seniority_input     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resume_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ jd_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">778</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ resume_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ jd_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   │\n",
       "│                     │                   │            │ job_family_input… │\n",
       "│                     │                   │            │ seniority_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">…</span> │\n",
       "│                     │                   │            │ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │    <span style=\"color: #00af00; text-decoration-color: #00af00\">199,424</span> │ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> │ dropout[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ dense_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
       "│ resume_input        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ jd_input            │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m384\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ job_family_input    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ seniority_input     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
       "│ (\u001b[38;5;33mInputLayer\u001b[0m)        │                   │            │                   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ lambda (\u001b[38;5;33mLambda\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ resume_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ jd_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ concatenate         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m778\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ resume_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m…\u001b[0m │\n",
       "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ jd_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   │\n",
       "│                     │                   │            │ job_family_input… │\n",
       "│                     │                   │            │ seniority_input[\u001b[38;5;34m…\u001b[0m │\n",
       "│                     │                   │            │ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │    \u001b[38;5;34m199,424\u001b[0m │ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]       │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m32,896\u001b[0m │ dropout[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ dense_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │      \u001b[38;5;34m8,256\u001b[0m │ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
       "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │         \u001b[38;5;34m65\u001b[0m │ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     │\n",
       "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,641</span> (940.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m240,641\u001b[0m (940.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">240,641</span> (940.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m240,641\u001b[0m (940.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1758166397.316219   55547 service.cc:148] XLA service 0x7f101c003a70 initialized for platform ROCM (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1758166397.316258   55547 service.cc:156]   StreamExecutor device (0): AMD Radeon RX 7900 XTX, AMDGPU ISA version: gfx1100\n",
      "2025-09-18 04:33:17.334579: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m24/50\u001b[0m \u001b[32m━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.5230 - loss: 0.6927"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1758166401.813909   55547 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 49ms/step - accuracy: 0.5156 - loss: 0.6920 - val_accuracy: 0.5375 - val_loss: 0.6900\n",
      "Epoch 2/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5444 - loss: 0.6894 - val_accuracy: 0.4950 - val_loss: 0.6902\n",
      "Epoch 3/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5681 - loss: 0.6853 - val_accuracy: 0.4875 - val_loss: 0.6884\n",
      "Epoch 4/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5813 - loss: 0.6806 - val_accuracy: 0.5425 - val_loss: 0.6848\n",
      "Epoch 5/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5906 - loss: 0.6771 - val_accuracy: 0.5425 - val_loss: 0.6835\n",
      "Epoch 6/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m-2s\u001b[0m -38680us/step - accuracy: 0.6000 - loss: 0.6723 - val_accuracy: 0.5550 - val_loss: 0.6782\n",
      "Epoch 7/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6225 - loss: 0.6602 - val_accuracy: 0.5700 - val_loss: 0.6754\n",
      "Epoch 8/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6269 - loss: 0.6544 - val_accuracy: 0.6075 - val_loss: 0.6596\n",
      "Epoch 9/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6456 - loss: 0.6430 - val_accuracy: 0.6050 - val_loss: 0.6619\n",
      "Epoch 10/10\n",
      "\u001b[1m50/50\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6488 - loss: 0.6296 - val_accuracy: 0.6275 - val_loss: 0.6444\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7f116c07e690>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate, Dropout, Lambda\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Load BERT model\n",
    "# ----------------------------\n",
    "bert_model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "embedding_dim = bert_model.get_sentence_embedding_dimension()\n",
    "\n",
    "# ----------------------------\n",
    "# 2. Extract data from df\n",
    "# ----------------------------\n",
    "resume_texts = df['resume_text_256'].tolist()\n",
    "jd_texts = df['jd_text_128'].tolist()\n",
    "job_family = df['job_family'].tolist()\n",
    "seniority = df['seniority'].tolist()\n",
    "advance = df['advance'].values\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Compute BERT embeddings\n",
    "# ----------------------------\n",
    "resume_embeddings = bert_model.encode(resume_texts, batch_size=32, show_progress_bar=True)\n",
    "jd_embeddings = bert_model.encode(jd_texts, batch_size=32, show_progress_bar=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 4. One-hot encode categorical features\n",
    "# ----------------------------\n",
    "ohe_job = OneHotEncoder(sparse_output=False)\n",
    "ohe_seniority = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "job_family_encoded = ohe_job.fit_transform(np.array(job_family).reshape(-1,1))\n",
    "seniority_encoded = ohe_seniority.fit_transform(np.array(seniority).reshape(-1,1))\n",
    "\n",
    "\n",
    "# ----------------------------\n",
    "# 5. Cosine similarity function\n",
    "# ----------------------------\n",
    "def cosine_similarity(a, b):\n",
    "    a_norm = tf.linalg.l2_normalize(a, axis=1)\n",
    "    b_norm = tf.linalg.l2_normalize(b, axis=1)\n",
    "    return tf.reduce_sum(a_norm * b_norm, axis=1, keepdims=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 6. Build Keras model\n",
    "# ----------------------------\n",
    "resume_input = Input(shape=(embedding_dim,), name='resume_input')\n",
    "jd_input = Input(shape=(embedding_dim,), name='jd_input')\n",
    "job_family_input = Input(shape=(job_family_encoded.shape[1],), name='job_family_input')\n",
    "seniority_input = Input(shape=(seniority_encoded.shape[1],), name='seniority_input')\n",
    "\n",
    "# Cosine similarity\n",
    "cos_sim = Lambda(lambda x: cosine_similarity(x[0], x[1]))([resume_input, jd_input])\n",
    "\n",
    "# Concatenate all features\n",
    "x = Concatenate()([resume_input, jd_input, job_family_input, seniority_input, cos_sim])\n",
    "\n",
    "# Dense layers\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(128, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "\n",
    "# Output layer\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[resume_input, jd_input, job_family_input, seniority_input],\n",
    "    outputs=output\n",
    ")\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# ----------------------------\n",
    "# 7. Train model\n",
    "# ----------------------------\n",
    "model.fit(\n",
    "    [resume_embeddings, jd_embeddings, job_family_encoded, seniority_encoded],\n",
    "    advance,\n",
    "    validation_split=0.2,\n",
    "    epochs=10,\n",
    "    batch_size=32\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20310932-f71a-4920-b033-8781c4c6bcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6805 - loss: 0.6087\n",
      "Test Loss: 0.6087, Test Accuracy: 0.6805\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the same data (or better: separate test set)\n",
    "loss, accuracy = model.evaluate(\n",
    "    [resume_embeddings, jd_embeddings, job_family_encoded, seniority_encoded],\n",
    "    advance,\n",
    "    batch_size=32\n",
    ")\n",
    "print(f\"Test Loss: {loss:.4f}, Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24ca9d25-5a90-4607-bb4f-4c5ff4386685",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step\n",
      "Predicted: 0, Actual: 1\n",
      "Predicted: 0, Actual: 0\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n",
      "Predicted: 1, Actual: 1\n"
     ]
    }
   ],
   "source": [
    "# Predict probabilities\n",
    "pred_probs = model.predict(\n",
    "    [resume_embeddings, jd_embeddings, job_family_encoded, seniority_encoded],\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "pred_classes = (pred_probs >= 0.5).astype(int)\n",
    "\n",
    "# Example\n",
    "for i in range(5):\n",
    "    print(f\"Predicted: {pred_classes[i][0]}, Actual: {advance[i]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "125e6aa6-8049-4896-86ff-e072afec1f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed0ca83272a7476ba31e87b209d8536a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d789c0fc6eb64819aa152ae576ea9afa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/63 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steveh/pytorch_rocm_env_new/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:62: UserWarning: The verbose parameter is deprecated. Please use get_last_lr() to access the learning rate.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100 | Train Loss: 0.6926 | Val Loss: 0.6921 | Val Acc: 0.4975\n",
      "Epoch 2/100 | Train Loss: 0.6907 | Val Loss: 0.6887 | Val Acc: 0.5450\n",
      "Epoch 3/100 | Train Loss: 0.6869 | Val Loss: 0.6856 | Val Acc: 0.5675\n",
      "Epoch 4/100 | Train Loss: 0.6780 | Val Loss: 0.6734 | Val Acc: 0.6450\n",
      "Epoch 5/100 | Train Loss: 0.6694 | Val Loss: 0.6596 | Val Acc: 0.6500\n",
      "Epoch 6/100 | Train Loss: 0.6548 | Val Loss: 0.6420 | Val Acc: 0.6625\n",
      "Epoch 7/100 | Train Loss: 0.6367 | Val Loss: 0.6196 | Val Acc: 0.6850\n",
      "Epoch 8/100 | Train Loss: 0.6184 | Val Loss: 0.5992 | Val Acc: 0.7075\n",
      "Epoch 9/100 | Train Loss: 0.5948 | Val Loss: 0.5956 | Val Acc: 0.6975\n",
      "Epoch 10/100 | Train Loss: 0.5816 | Val Loss: 0.5555 | Val Acc: 0.7400\n",
      "Epoch 11/100 | Train Loss: 0.5634 | Val Loss: 0.5320 | Val Acc: 0.7625\n",
      "Epoch 12/100 | Train Loss: 0.5368 | Val Loss: 0.5174 | Val Acc: 0.7725\n",
      "Epoch 13/100 | Train Loss: 0.5254 | Val Loss: 0.5075 | Val Acc: 0.7600\n",
      "Epoch 14/100 | Train Loss: 0.5058 | Val Loss: 0.5241 | Val Acc: 0.7350\n",
      "Epoch 15/100 | Train Loss: 0.5001 | Val Loss: 0.4908 | Val Acc: 0.7700\n",
      "Epoch 16/100 | Train Loss: 0.4798 | Val Loss: 0.4754 | Val Acc: 0.7900\n",
      "Epoch 17/100 | Train Loss: 0.4818 | Val Loss: 0.4747 | Val Acc: 0.7850\n",
      "Epoch 18/100 | Train Loss: 0.4591 | Val Loss: 0.4622 | Val Acc: 0.7850\n",
      "Epoch 19/100 | Train Loss: 0.4559 | Val Loss: 0.4608 | Val Acc: 0.7850\n",
      "Epoch 20/100 | Train Loss: 0.4525 | Val Loss: 0.4540 | Val Acc: 0.7975\n",
      "Epoch 21/100 | Train Loss: 0.4515 | Val Loss: 0.4924 | Val Acc: 0.7575\n",
      "Epoch 22/100 | Train Loss: 0.4464 | Val Loss: 0.4549 | Val Acc: 0.7900\n",
      "Epoch 23/100 | Train Loss: 0.4320 | Val Loss: 0.4526 | Val Acc: 0.7825\n",
      "Epoch 24/100 | Train Loss: 0.4276 | Val Loss: 0.4465 | Val Acc: 0.7925\n",
      "Epoch 25/100 | Train Loss: 0.4107 | Val Loss: 0.4442 | Val Acc: 0.7900\n",
      "Epoch 26/100 | Train Loss: 0.4115 | Val Loss: 0.4366 | Val Acc: 0.8000\n",
      "Epoch 27/100 | Train Loss: 0.4020 | Val Loss: 0.4343 | Val Acc: 0.8025\n",
      "Epoch 28/100 | Train Loss: 0.3962 | Val Loss: 0.4296 | Val Acc: 0.8100\n",
      "Epoch 29/100 | Train Loss: 0.3863 | Val Loss: 0.4334 | Val Acc: 0.8025\n",
      "Epoch 30/100 | Train Loss: 0.3875 | Val Loss: 0.4386 | Val Acc: 0.7825\n",
      "Epoch 31/100 | Train Loss: 0.3828 | Val Loss: 0.4267 | Val Acc: 0.8075\n",
      "Epoch 32/100 | Train Loss: 0.3873 | Val Loss: 0.4337 | Val Acc: 0.7875\n",
      "Epoch 33/100 | Train Loss: 0.3615 | Val Loss: 0.4379 | Val Acc: 0.7800\n",
      "Epoch 34/100 | Train Loss: 0.3584 | Val Loss: 0.4238 | Val Acc: 0.8025\n",
      "Epoch 35/100 | Train Loss: 0.3518 | Val Loss: 0.4239 | Val Acc: 0.7975\n",
      "Epoch 36/100 | Train Loss: 0.3557 | Val Loss: 0.4206 | Val Acc: 0.8050\n",
      "Epoch 37/100 | Train Loss: 0.3482 | Val Loss: 0.4166 | Val Acc: 0.8050\n",
      "Epoch 38/100 | Train Loss: 0.3493 | Val Loss: 0.4181 | Val Acc: 0.7975\n",
      "Epoch 39/100 | Train Loss: 0.3390 | Val Loss: 0.4126 | Val Acc: 0.8000\n",
      "Epoch 40/100 | Train Loss: 0.3315 | Val Loss: 0.4094 | Val Acc: 0.7975\n",
      "Epoch 41/100 | Train Loss: 0.3308 | Val Loss: 0.4145 | Val Acc: 0.7975\n",
      "Epoch 42/100 | Train Loss: 0.3150 | Val Loss: 0.4152 | Val Acc: 0.7975\n",
      "Epoch 43/100 | Train Loss: 0.3254 | Val Loss: 0.4128 | Val Acc: 0.7900\n",
      "Epoch 44/100 | Train Loss: 0.3072 | Val Loss: 0.4267 | Val Acc: 0.8100\n",
      "Epoch 45/100 | Train Loss: 0.3073 | Val Loss: 0.4123 | Val Acc: 0.8075\n",
      "Epoch 46/100 | Train Loss: 0.2988 | Val Loss: 0.4278 | Val Acc: 0.8025\n",
      "Epoch 47/100 | Train Loss: 0.2864 | Val Loss: 0.4156 | Val Acc: 0.7950\n",
      "Epoch 48/100 | Train Loss: 0.2784 | Val Loss: 0.4227 | Val Acc: 0.8175\n",
      "Epoch 49/100 | Train Loss: 0.2722 | Val Loss: 0.4118 | Val Acc: 0.7875\n",
      "Epoch 50/100 | Train Loss: 0.2716 | Val Loss: 0.4101 | Val Acc: 0.7950\n",
      "Early stopping triggered at epoch 50\n",
      "\n",
      "Validation Results:\n",
      "[[168  43]\n",
      " [ 39 150]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.81      0.80      0.80       211\n",
      "         1.0       0.78      0.79      0.79       189\n",
      "\n",
      "    accuracy                           0.80       400\n",
      "   macro avg       0.79      0.79      0.79       400\n",
      "weighted avg       0.80      0.80      0.80       400\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# Optimized PyTorch + SentenceTransformer Pipeline\n",
    "# ============================================================\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# ----------------------------\n",
    "# 1️⃣ Load dataset\n",
    "# ----------------------------\n",
    "df = pd.read_csv(DATA_INPUT)\n",
    "\n",
    "# ----------------------------\n",
    "# 2️⃣ Feature engineering\n",
    "# ----------------------------\n",
    "def extract_years(resume_text):\n",
    "    match = re.search(r'(\\d+)\\+?\\s*years', resume_text)\n",
    "    return int(match.group(1)) if match else 0\n",
    "\n",
    "df['years_experience'] = df['resume_text_256'].apply(extract_years)\n",
    "\n",
    "skills_list = ['Python','AWS','DevOps','QA','Frontend','Backend','PM']\n",
    "\n",
    "def skill_overlap(resume, jd):\n",
    "    resume_skills = set(s.lower() for s in skills_list if s.lower() in resume.lower())\n",
    "    jd_skills = set(s.lower() for s in skills_list if s.lower() in jd.lower())\n",
    "    return len(resume_skills & jd_skills) / (len(jd_skills) + 1e-6)\n",
    "\n",
    "df['skill_overlap'] = df.apply(lambda row: skill_overlap(row['resume_text_256'], row['jd_text_128']), axis=1)\n",
    "\n",
    "# ----------------------------\n",
    "# 3️⃣ Encode categorical features\n",
    "# ----------------------------\n",
    "ohe_job = OneHotEncoder(sparse_output=False)\n",
    "ohe_seniority = OneHotEncoder(sparse_output=False)\n",
    "\n",
    "job_family_encoded = ohe_job.fit_transform(df[['job_family']])\n",
    "seniority_encoded = ohe_seniority.fit_transform(df[['seniority']])\n",
    "\n",
    "numeric_features = np.stack([df['years_experience'], df['skill_overlap']], axis=1)\n",
    "\n",
    "# ----------------------------\n",
    "# 4️⃣ Sentence embeddings\n",
    "# ----------------------------\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using device:\", device)\n",
    "\n",
    "sbert_model = SentenceTransformer('all-MiniLM-L6-v2', device=device)\n",
    "\n",
    "resume_embeddings = sbert_model.encode(list(df['resume_text_256']), batch_size=32, show_progress_bar=True, convert_to_numpy=True)\n",
    "jd_embeddings = sbert_model.encode(list(df['jd_text_128']), batch_size=32, show_progress_bar=True, convert_to_numpy=True)\n",
    "\n",
    "# ----------------------------\n",
    "# 5️⃣ Dataset class\n",
    "# ----------------------------\n",
    "class ResumeDataset(Dataset):\n",
    "    def __init__(self, resumes, jds, job_family, seniority, numeric_feats, labels):\n",
    "        self.resumes = torch.tensor(resumes, dtype=torch.float32)\n",
    "        self.jds = torch.tensor(jds, dtype=torch.float32)\n",
    "        self.job_family = torch.tensor(job_family, dtype=torch.float32)\n",
    "        self.seniority = torch.tensor(seniority, dtype=torch.float32)\n",
    "        self.numeric_feats = torch.tensor(numeric_feats, dtype=torch.float32)\n",
    "        self.labels = torch.tensor(labels, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return (self.resumes[idx], self.jds[idx], self.job_family[idx],\n",
    "                self.seniority[idx], self.numeric_feats[idx], self.labels[idx])\n",
    "\n",
    "# ----------------------------\n",
    "# 6️⃣ Train/Validation split\n",
    "# ----------------------------\n",
    "X_train_res, X_val_res, X_train_jd, X_val_jd, X_train_job, X_val_job, \\\n",
    "X_train_senior, X_val_senior, X_train_num, X_val_num, y_train, y_val = train_test_split(\n",
    "    resume_embeddings, jd_embeddings, job_family_encoded, seniority_encoded, numeric_features,\n",
    "    df['advance'].values, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "train_dataset = ResumeDataset(X_train_res, X_train_jd, X_train_job, X_train_senior, X_train_num, y_train)\n",
    "val_dataset = ResumeDataset(X_val_res, X_val_jd, X_val_job, X_val_senior, X_val_num, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "# ----------------------------\n",
    "# 7️⃣ Neural network\n",
    "# ----------------------------\n",
    "class AdvancePredictor(nn.Module):\n",
    "    def __init__(self, resume_dim, jd_dim, job_dim, seniority_dim, numeric_dim):\n",
    "        super().__init__()\n",
    "        input_dim = resume_dim + jd_dim + job_dim + seniority_dim + numeric_dim + 1  # cosine similarity\n",
    "        self.fc1 = nn.Linear(input_dim, 128)\n",
    "        self.dropout1 = nn.Dropout(0.3)\n",
    "        self.fc2 = nn.Linear(128, 64)\n",
    "        self.dropout2 = nn.Dropout(0.3)\n",
    "        self.out = nn.Linear(64, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, resume, jd, job, seniority, numeric):\n",
    "        cos_sim = torch.sum(resume*jd, dim=1, keepdim=True) / (\n",
    "            torch.norm(resume, dim=1, keepdim=True) * torch.norm(jd, dim=1, keepdim=True) + 1e-6)\n",
    "        x = torch.cat([resume, jd, job, seniority, numeric, cos_sim], dim=1)\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.sigmoid(self.out(x))\n",
    "        return x\n",
    "\n",
    "model = AdvancePredictor(\n",
    "    resume_dim=resume_embeddings.shape[1],\n",
    "    jd_dim=jd_embeddings.shape[1],\n",
    "    job_dim=job_family_encoded.shape[1],\n",
    "    seniority_dim=seniority_encoded.shape[1],\n",
    "    numeric_dim=numeric_features.shape[1]\n",
    ").to(device)\n",
    "\n",
    "# ----------------------------\n",
    "# 8️⃣ Training setup\n",
    "# ----------------------------\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=5, factor=0.5, verbose=True)\n",
    "num_epochs = 100\n",
    "early_stop_patience = 10\n",
    "best_val_loss = np.inf\n",
    "epochs_no_improve = 0\n",
    "\n",
    "# ----------------------------\n",
    "# 9️⃣ Training loop with early stopping\n",
    "# ----------------------------\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for resumes, jds, jobs, seniors, numerics, labels in train_loader:\n",
    "        resumes, jds, jobs, seniors, numerics, labels = resumes.to(device), jds.to(device), \\\n",
    "                                                        jobs.to(device), seniors.to(device), \\\n",
    "                                                        numerics.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(resumes, jds, jobs, seniors, numerics)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item() * labels.size(0)\n",
    "\n",
    "    train_loss /= len(train_loader.dataset)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_labels = []\n",
    "    with torch.no_grad():\n",
    "        for resumes, jds, jobs, seniors, numerics, labels in val_loader:\n",
    "            resumes, jds, jobs, seniors, numerics, labels = resumes.to(device), jds.to(device), \\\n",
    "                                                            jobs.to(device), seniors.to(device), \\\n",
    "                                                            numerics.to(device), labels.to(device)\n",
    "            outputs = model(resumes, jds, jobs, seniors, numerics)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item() * labels.size(0)\n",
    "            val_preds.append(outputs.cpu())\n",
    "            val_labels.append(labels.cpu())\n",
    "\n",
    "    val_loss /= len(val_loader.dataset)\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_labels = torch.cat(val_labels)\n",
    "    val_pred_classes = (val_preds >= 0.5).int()\n",
    "    val_accuracy = (val_pred_classes == val_labels.int()).float().mean()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Acc: {val_accuracy:.4f}\")\n",
    "\n",
    "    # Early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"advance_predictor_best.pt\")\n",
    "        epochs_no_improve = 0\n",
    "    else:\n",
    "        epochs_no_improve += 1\n",
    "        if epochs_no_improve >= early_stop_patience:\n",
    "            print(f\"Early stopping triggered at epoch {epoch+1}\")\n",
    "            break\n",
    "\n",
    "# ----------------------------\n",
    "# 10️⃣ Evaluation\n",
    "# ----------------------------\n",
    "print(\"\\nValidation Results:\")\n",
    "print(confusion_matrix(val_labels, val_pred_classes))\n",
    "print(classification_report(val_labels, val_pred_classes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb83ee5-b97f-400b-9625-7fc7e80562a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
